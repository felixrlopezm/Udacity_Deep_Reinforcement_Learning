{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 3: Collaboration and Competition. Tennis\n",
    "\n",
    "---\n",
    "\n",
    "### Preliminary actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cpu\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from collections import deque\n",
    "from unityagents import UnityEnvironment\n",
    "\n",
    "from maddpg_agent import MADDGP_Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**IMPORTANT**: introduce in the following cell, the path to place where you have stored the file of the TENNIS evironment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\t\n",
      "Unity brain name: TennisBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 8\n",
      "        Number of stacked Vector Observation: 3\n",
      "        Vector Action space type: continuous\n",
      "        Vector Action space size (per agent): 2\n",
      "        Vector Action descriptions: , \n"
     ]
    }
   ],
   "source": [
    "# Launching the environment\n",
    "env = UnityEnvironment(file_name='Tennis.app')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Environments contain **_brains_** which are responsible for deciding the actions of their associated agents. Here we check for the first brain available, and set it as the default brain we will be controlling from Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of available brains: 1\n",
      "Name of the brains: ['TennisBrain']\n",
      "Unity brain name: TennisBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 8\n",
      "        Number of stacked Vector Observation: 3\n",
      "        Vector Action space type: continuous\n",
      "        Vector Action space size (per agent): 2\n",
      "        Vector Action descriptions: , \n"
     ]
    }
   ],
   "source": [
    "# Get and select the default brain\n",
    "brain_names = env.brain_names\n",
    "print('Number of available brains:',len(brain_names))\n",
    "print('Name of the brains:',brain_names)\n",
    "\n",
    "brain_name = brain_names[0]          # Get the name of the first brain\n",
    "brain = env.brains[brain_name]       # Initizlize the brain\n",
    "print(brain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of agents: 2\n",
      "Size of action space (per agent): 2\n",
      "There are 2 agents. Each observes a state with length: 24\n",
      "The state of any of the agents is made of 8 dimensions x 3 stacked observations = 24 values,\n",
      "and it looks likes this [ 0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.         -6.65278625 -1.5\n",
      " -0.          0.          6.83172083  6.         -0.          0.        ]\n"
     ]
    }
   ],
   "source": [
    "# Reset the environment\n",
    "env_data = env.reset(train_mode=True)[brain_name]\n",
    "\n",
    "# Number of agents in the environment\n",
    "num_agents = len(env_data.agents)\n",
    "print('Number of agents:', num_agents)\n",
    "\n",
    "# size of the action space (per agent)\n",
    "action_size = brain.vector_action_space_size\n",
    "print('Size of action space (per agent):', action_size)\n",
    "\n",
    "# Size fo the state space \n",
    "states = env_data.vector_observations\n",
    "state_size = states.shape[1]\n",
    "print('There are {} agents. Each observes a state with length: {}'.format(states.shape[0], state_size))\n",
    "print('The state of any of the agents is made of 8 dimensions x 3 stacked observations = 24 values,')\n",
    "print('and it looks likes this', states[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Agent with MADDPG algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters definition\n",
    "hyperparameters = {\n",
    "    'FC1': 190,               # Actor/Critic network: nodes at 1st hidden layer\n",
    "    'FC2': 160,               # Actor/Critic network: nodes at 2nd hidden layer\n",
    "    'BUFFER_SIZE': int(1e6),  # Replay buffer size\n",
    "    'BATCH_SIZE': 256,        # Minibatch size\n",
    "    'GAMMA': 0.99,            # Discount factor\n",
    "    'TAU': 5e-3,              # For soft update of target parameters\n",
    "    'LR_ACTOR': 1e-4,         # Learning rate of the actor\n",
    "    'LR_CRITIC': 5e-4,        # Learning rate of the critic\n",
    "    'WEIGHT_DECAY': 1e-6,     # Critic network L2 weight decay\n",
    "    'UPDATE_EVERY': 1,        # Update rate\n",
    "    'N_UPDATES': 1,           # Update passes\n",
    "    'MU': 0.0,                # Parameter for Ornstein-Uhlenbeck noise\n",
    "    'SIGMA': 0.20,            # Parameter for Ornstein-Uhlenbeck noise\n",
    "    'THETA': 0.15,            # Parameter for Ornstein-Uhlenbeck noise\n",
    "    'RANDOM_SEED': 4,         # Seed for random generation (to allow repetitiveness)\n",
    "    'EPS_INT': 800            # Interval of episodes to decay de noise epsilon (from 1 to 0) \n",
    "     }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the MADDPG agent (from maddpg_agent.py file)\n",
    "agent = MADDGP_Agent(num_agents=num_agents, state_size=state_size, action_size=action_size, \n",
    "                hyperparameters=hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the training process\n",
    "def maddpg_training(agent, n_episodes=2000, print_every=100):\n",
    "                                                # Initialize:\n",
    "    scores_mean_log = []                        #      list for the log of mean scores\n",
    "    scores_window = deque(maxlen=100)           #      list of last 100 scores\n",
    "    scores = []                                 #      list containing score for each episode\n",
    "    not_solved = True                           #      not_solved control\n",
    "    solved_episode = 0                          #      episode for average score over threshold\n",
    "    solved_av_score = 0                         #      average score when solved\n",
    "    max_av_score = float(\"-inf\")                #      maximum average score\n",
    "    max_av_score_episode = 0                    #      episode at maximum average score\n",
    "    \n",
    "    \n",
    "    for i_episode in range(1, n_episodes+1):                # Episode loop\n",
    "        env_data = env.reset(train_mode=True)[brain_name]   # Reset environment in TRAINING MODE\n",
    "        states = env_data.vector_observations               # Get the first state\n",
    "        agent.reset()                                       # Reset smart agent (= noise process)\n",
    "        \n",
    "        score = np.zeros(num_agents)                        # Initialize score counter\n",
    "        t = 1                                               # Initialize time step counter\n",
    "        \n",
    "        while True:                                         # Trajectory loop\n",
    "            actions = agent.act(states, i_episode,\n",
    "                                add_noise=True)             # Get actions from policy (one per agent)\n",
    "            env_data = env.step(actions)[brain_name]        # Interaction with the environment\n",
    "            \n",
    "            next_states = env_data.vector_observations      # Get the next state (one per agent)\n",
    "            rewards = env_data.rewards                      # Get the reward (one per agent)\n",
    "            dones = env_data.local_done                     # Get the done code (one per agent)\n",
    "\n",
    "            agent.step(states, actions, rewards, next_states, dones)   # Agents' process: gather experiences and learn\n",
    "            \n",
    "            score += rewards                               # Add time step reward to total trajectory score\n",
    "            t += 1                                         # Update of time step counter\n",
    "            \n",
    "            if np.any(dones):                              # Break trajectory loop when episode finishes (done=True)\n",
    "                break\n",
    "                \n",
    "            states = next_states                           # Roll over states for next iteration\n",
    "    \n",
    "        max_score = np.max(score)                          # Evaluate max score of the match from every agent's score\n",
    "        scores.append(max_score)                           # Add max-agent score to score log\n",
    "        scores_window.append(max_score)                    # Add max-agent score to last 100 scores log\n",
    "        scores_mean_log.append(np.mean(scores_window))     # Add mean of the last 100 scores to the log of mean scores\n",
    "        \n",
    "        # Printing training log\n",
    "        print('\\rEpisode {}\\tAverage Score: {:.3f}\\tMax Score: {:.3f}\\tScore: {}\\tGame-steps: {:d} '\n",
    "              .format(i_episode, np.mean(scores_window), max_score, score, t), end='')\n",
    "        \n",
    "        if i_episode % print_every == 0:\n",
    "            print('\\rEpisode {}\\tAverage Score: {:.3f}\\t                  \\t                   \\t                \\t                '\n",
    "                  .format(i_episode, np.mean(scores_window)))\n",
    "        \n",
    "        # Determination if problem solved\n",
    "        if (np.mean(scores_window) >= 0.5) and not_solved:\n",
    "            solved_episode = i_episode\n",
    "            solved_av_score = np.mean(scores_window)\n",
    "            not_solved = False\n",
    "            \n",
    "        # Saving agent and critic checkpoint files with every new max 100-last average socre\n",
    "        if np.mean(scores_window) >= max_av_score:\n",
    "            max_av_score = np.mean(scores_window)\n",
    "            max_av_score_episode = i_episode\n",
    "            for i in range(num_agents):\n",
    "                torch.save(agent.ddpg_agents[i].actor_local.state_dict(), 'trained_actor_{:d}-maddpg.pth'.format(i))\n",
    "                torch.save(agent.ddpg_agents[i].critic_local.state_dict(), 'trained_critic_{:d}-maddpg.pth'.format(i))\n",
    "        \n",
    "        # Stopping the learning process if no improvement in the last 200 episodes\n",
    "        if not_solved == False and i_episode > (max_av_score_episode + 200) and np.mean(scores_window) < max_av_score:\n",
    "            break\n",
    "    \n",
    "    # Printing summary\n",
    "    print('\\n')        \n",
    "    print('Problem solved in {:d} episodes when reached an average score of {:.3f}'.format(solved_episode, solved_av_score))\n",
    "    print('Maximum average score {:.3f}, reached at episode {:d}'.format(max_av_score, max_av_score_episode))\n",
    "            \n",
    "    return scores, scores_mean_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 100\tAverage Score: 0.000\t                  \t                   \t                \t                \n",
      "Episode 200\tAverage Score: 0.011\t                  \t                   \t                \t                \n",
      "Episode 300\tAverage Score: 0.023\t                  \t                   \t                \t                \n",
      "Episode 400\tAverage Score: 0.074\t                  \t                   \t                \t                \n",
      "Episode 500\tAverage Score: 0.102\t                  \t                   \t                \t                \n",
      "Episode 600\tAverage Score: 0.099\t                  \t                   \t                \t                \n",
      "Episode 700\tAverage Score: 0.110\t                  \t                   \t                \t                \n",
      "Episode 800\tAverage Score: 0.122\t                  \t                   \t                \t                \n",
      "Episode 900\tAverage Score: 0.154\t                  \t                   \t                \t                \n",
      "Episode 1000\tAverage Score: 0.240\t                  \t                   \t                \t                \n",
      "Episode 1100\tAverage Score: 1.441\t                  \t                   \t                \t                \n",
      "Episode 1200\tAverage Score: 1.970\t                  \t                   \t                \t                \n",
      "Episode 1300\tAverage Score: 1.426\t                  \t                   \t                \t                \n",
      "Episode 1400\tAverage Score: 1.679\t                  \t                   \t                \t                \n",
      "Episode 1426\tAverage Score: 1.703\tMax Score: 2.600\tScore: [2.60000004 2.60000004]\tGame-steps: 1002 \n",
      "\n",
      "Problem solved in 1023 episodes when reached an average score of 0.504\n",
      "Maximum average score 2.004, reached at episode 1225\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Lauching the training process\n",
    "scores, scores_mean_log = maddpg_training(agent, n_episodes=3000)\n",
    "\n",
    "# Ploting the scores evolution during training.\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.plot(np.arange(1, len(scores)+1), scores, label='episode max s')\n",
    "plt.plot(np.arange(1, len(scores)+1), scores_mean_log, c='r', label='100-last-score mean')\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Episode #')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking agent performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load actor and critic weights from file (if needed)\n",
    "#agent = MADDGP_Agent(num_agents=num_agents, state_size=state_size, action_size=action_size, \n",
    "#                hyperparameters=hyperparameters)\n",
    "\n",
    "#for i in range(num_agents):\n",
    "#    agent.ddpg_agents[i].actor_local.load_state_dict(torch.load('trained_actor_{:d}-maddpg.pth'.format(i)))\n",
    "#    agent.ddpg_agents[i].critic_local.load_state_dict(torch.load('trained_critic_{:d}-maddpg.pth'.format(i)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score (max over agents) at episode 1: 2.700000\n",
      "Score (max over agents) at episode 2: 2.600000\n",
      "Score (max over agents) at episode 3: 2.700000\n",
      "Score (max over agents) at episode 4: 2.600000\n",
      "Score (max over agents) at episode 5: 2.700000\n",
      "\n",
      "Smart Agent average score after 5 episodes: 2.66\n"
     ]
    }
   ],
   "source": [
    "# Checking the performance of the trained agent\n",
    "scores_log = []\n",
    "test_episodes = 5\n",
    "\n",
    "for i in range(0, test_episodes):                          # play game for a number of episodes\n",
    "\n",
    "    scores = np.zeros(num_agents)                          # initialize the score (for each agent)\n",
    "    \n",
    "    env_info = env.reset(train_mode=False)[brain_name]     # reset the environment    \n",
    "    states = env_info.vector_observations                  # get the current state (for each agent)\n",
    "\n",
    "    while True:                                            # play loop\n",
    "        actions = agent.act(states, i, add_noise=False)       # get actions from trained agent\n",
    "        env_data = env.step(actions)[brain_name]           # interact with the environment\n",
    "        \n",
    "        next_states = env_data.vector_observations         # get next state (for each agent)\n",
    "        rewards = env_data.rewards                         # get reward (for each agent)\n",
    "        dones = env_data.local_done                        # see if episode finished\n",
    "        \n",
    "        scores += env_data.rewards                         # update the score (for each agent)\n",
    "        states = next_states                               # roll over states to next time step\n",
    "        \n",
    "        if np.any(dones):                                  # exit loop if episode finished\n",
    "            break\n",
    "            \n",
    "    scores_log.append(np.max(scores))\n",
    "    \n",
    "    print('Score (max over agents) at episode {:d}: {:2f}'.format(i+1, np.max(scores)))\n",
    "\n",
    "\n",
    "print('\\nSmart Agent average score after {:d} episodes: {:.2f}'.format(test_episodes, np.mean(scores_log)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score (max over all agents) at episode 1: 0.000000\n",
      "Score (max over all agents) at episode 2: 0.100000\n",
      "Score (max over all agents) at episode 3: 0.000000\n",
      "Score (max over all agents) at episode 4: 0.000000\n",
      "Score (max over all agents) at episode 5: 0.090000\n",
      "\n",
      "Average score after 5 episodes: 0.038000\n"
     ]
    }
   ],
   "source": [
    "# Checking the performance of the random agent\n",
    "scores_log = []\n",
    "test_episodes = 5\n",
    "\n",
    "for i in range(0, test_episodes):                          # play game for a number of episodes\n",
    "    scores = np.zeros(num_agents)                          # initialize the score (for each agent)\n",
    "    \n",
    "    env_info = env.reset(train_mode=False)[brain_name]     # reset the environment    \n",
    "    states = env_info.vector_observations                  # get the current state (for each agent)\n",
    "\n",
    "    while True:                                            # play loop\n",
    "        actions = np.random.randn(num_agents, action_size) # get random actions (for each agent)\n",
    "        actions = np.clip(actions, -1, 1)                  # clip all actions between -1 and 1\n",
    "        env_info = env.step(actions)[brain_name]           # interact with the environment\n",
    "        \n",
    "        next_states = env_info.vector_observations         # get next state (for each agent)\n",
    "        rewards = env_info.rewards                         # get reward (for each agent)\n",
    "        dones = env_info.local_done                        # see if episode finished\n",
    "        \n",
    "        scores += env_info.rewards                         # update the score (for each agent)\n",
    "        states = next_states                               # roll over states to next time step\n",
    "        \n",
    "        if np.any(dones):                                  # exit loop if episode finished\n",
    "            break\n",
    "            \n",
    "    scores_log.append(np.max(scores))\n",
    "    \n",
    "    print('Score (max over all agents) at episode {:d}: {:2f}'.format(i+1, np.max(scores)))\n",
    "    \n",
    "print('\\nAverage score after {:d} episodes: {:2f}'.format(test_episodes, np.mean(scores_log)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Closing the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close the environment\n",
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drlnd",
   "language": "python",
   "name": "drlnd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
